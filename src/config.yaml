# config.yaml

device: auto

model:
  window_size: 8
  num_heads: 4
  scale: 4
  dim: 56
  num_blocks: 3 # original paper has 6 i think

training:
  epochs: 1000
  batch_size: 32
  learning_rate: 0.0005
  num_workers: 4
  beta1: 0.9
  beta2: 0.999
  epsilon: 0.00000001
  lr_decay_step: 200
  lr_decay_gamma: 0.5
  val_interval: 1

dataset:
  root_dir: "src/data/DIV2K"
  scale: 4
  train_patch_size: 64
  val_patch_size: null
  augment: true
  val_subset_size: 10

optimizer:
  type: adam
